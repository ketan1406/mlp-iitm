{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Q1 Load the dataset.\n",
        "\n",
        "The file has no index column.\n",
        "The last column is the target column.\n",
        "The first row of the file has column ids\n",
        "\n",
        "Click here to view the dataset\n",
        "\n",
        "Which dataset are you using for this exam?\n",
        "\n",
        "\n",
        "NPPE1_ModelBuilding3.csv"
      ],
      "metadata": {
        "id": "JsMhhmcyFJzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----- Mount Drive and Load Dataset -----\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Change the file name if you wish to use a different dataset.\n",
        "data_path = '/content/drive/MyDrive/MLP/NPPE-1/Model-building/NPPE1_ModelBuilding3.csv'\n",
        "df_model = pd.read_csv(data_path)\n",
        "print(\"Dataset loaded. Columns:\", df_model.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUtpIS7MF9UF",
        "outputId": "e72d20d4-568a-452d-bef1-e2ee6c8161ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Dataset loaded. Columns: Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12',\n",
            "       '13', '14'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q2 Split the dataset into train dataset and test dataset in the following manner\n",
        "\n",
        "  Use train_test_split to split the dataset into train and test dataset with test size equal to 0.3(i.e.30%) and random_state equal to 42. Let other parameters have default values.\n",
        "\n",
        "  Columns except the last column should be the feature matrix (X_train or X_test)\n",
        "  \n",
        "  Last column will be the label vector.\n",
        "\n",
        "(Common instructions for Q.2, Q.3 and Q.4)"
      ],
      "metadata": {
        "id": "xfbYW-EwFzlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----- Split the Dataset into Features and Target -----\n",
        "# The file has no index column, and the last column is the target.\n",
        "X = df_model.iloc[:, :-1]   # All columns except the last one\n",
        "y = df_model.iloc[:, -1]    # The last column as target\n",
        "\n",
        "# Split into training and test sets (70% train, 30% test) using random_state=42\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "print(\"Training set samples:\", X_train.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhRLZYZzGzDs",
        "outputId": "0febb224-ca04-4afe-a644-33dfec0419cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set samples: 2800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the ridge model on the training data with the following parameters:\n",
        "\n",
        "alpha = 10\n",
        "\n",
        "solver = 'saga'\n",
        "\n",
        "tol = 1e-4\n",
        "\n",
        "random_state = 42\n",
        "\n",
        "Enter the value of $R^2$ score on the test dataset."
      ],
      "metadata": {
        "id": "nSOdy3d6Fzzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# Train Ridge model with given parameters\n",
        "ridge = Ridge(alpha=10, solver='saga', tol=1e-4, random_state=42)\n",
        "ridge.fit(X_train, y_train)\n",
        "r2_ridge = ridge.score(X_test, y_test)\n",
        "print(\"R^2 score of Ridge model on test set:\", r2_ridge)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CR7uzQB9HRdr",
        "outputId": "5091d4f8-ac8a-4e0d-b3ed-44c645c1c2cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R^2 score of Ridge model on test set: 0.6613547575262211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q3 What is the index of most important feature? Note the index starts from 0. Ignore the intercept for this question."
      ],
      "metadata": {
        "id": "AChNuAvPFzWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coef = ridge.coef_\n",
        "most_important_index = np.argmax(np.abs(coef))\n",
        "print(\"Index of most important feature:\", most_important_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjM6Sh9YH8jp",
        "outputId": "c1231021-fbea-404c-af14-00ff6e90b3e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index of most important feature: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q4 What is the index of least important feature? Note the index starts from 0. Ignore the intercept for this question.\n"
      ],
      "metadata": {
        "id": "yidYMOHjFzJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "least_important_index = np.argmin(np.abs(coef))\n",
        "print(\"Index of least important feature:\", least_important_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o70WreStIJZA",
        "outputId": "8bd27d30-5ee9-4808-a51b-6abd0fba5f39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index of least important feature: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q5 (Common Instructions for Q.5 and Q.6)\n",
        "Take SGDRegressor(random_state = 42) estimator with GridSearchCV. Hyperparameter tuning to be done over the following parameters:\n",
        "penalty as ['l1', 'l2']\n",
        "alpha values as [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
        "values of tol as [1e-4, 1e-3, 1e-2, 1e-1]\n",
        "Use cross-validation = 5\n",
        "Set scoring as neg_mean_absolute_error\n",
        "Use the best model from above hyper parameter tuning process to answer following questions:\n",
        "\n",
        "What is the best penalty?"
      ],
      "metadata": {
        "id": "D7gBaVbiFy6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'alpha': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1],\n",
        "    'tol': [1e-4, 1e-3, 1e-2, 1e-1]\n",
        "}\n",
        "\n",
        "sgd = SGDRegressor(random_state=42)\n",
        "grid = GridSearchCV(sgd, param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "best_penalty = grid.best_params_['penalty']\n",
        "print(\"Best penalty from GridSearchCV:\", best_penalty)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LD5F_m1nIghb",
        "outputId": "4bf4587f-2d78-414a-ad8f-e1a9e579ea02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best penalty from GridSearchCV: l2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q6 What will be value of mean absolute error on the test dataset?"
      ],
      "metadata": {
        "id": "WS7c3T-xFypD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test set and compute Mean Absolute Error\n",
        "y_pred_sgd = grid.best_estimator_.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred_sgd)\n",
        "print(\"Mean Absolute Error on test set for best SGDRegressor:\", mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGTY-qTwI6eH",
        "outputId": "d85e419b-2588-4263-9587-a363d90196a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error on test set for best SGDRegressor: 3.8131121797994014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q7 (Common Instructions for Q.7 and Q.8)\n",
        "Create a pipeline of the PCA() as transformer and Lasso as an estimator.\n",
        "Use GridSearchCV for tuning the hyperparameters of the created pipeline on training dataset.\n",
        "\tValues of n_components for PCA to be [0.9, 0.95]\n",
        "\tlasso alpha value to be taken as : [10, 1, 0.01, 0.001]\n",
        "\tscoring : neg_mean_absolute_error.\n",
        "\tUse 5 fold cross validation.\n",
        "\tn_jobs = -1 (negative one) [it helps in using all the computational power to run this job]\n",
        "(Note: Kindly ignore the warning.)\n",
        "\n",
        "If we fit the pipeline on the training dataset, what will be the R2 score on the test dataset?"
      ],
      "metadata": {
        "id": "pa6rNisiFyTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create the pipeline with PCA and Lasso\n",
        "pipeline = Pipeline([\n",
        "    ('pca', PCA()),\n",
        "    ('lasso', Lasso(random_state=42))\n",
        "])\n",
        "\n",
        "# Define parameter grid for PCA n_components and Lasso alpha\n",
        "param_grid_pipeline = {\n",
        "    'pca__n_components': [0.9, 0.95],\n",
        "    'lasso__alpha': [10, 1, 0.01, 0.001]\n",
        "}\n",
        "\n",
        "grid_pipeline = GridSearchCV(pipeline, param_grid_pipeline, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
        "grid_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate R^2 score on test set using the best pipeline model\n",
        "r2_pipeline = grid_pipeline.best_estimator_.score(X_test, y_test)\n",
        "print(\"R^2 score on test dataset from PCA + Lasso pipeline:\", r2_pipeline)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0qLgzNrJGYD",
        "outputId": "e808cbcb-e3f6-43ec-8f2b-e7bd5b08853c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R^2 score on test dataset from PCA + Lasso pipeline: 0.6288625430197575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q8 How much variance is explained (Eigen value) by the first principle component?"
      ],
      "metadata": {
        "id": "oNsALvY6Fx51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_pca = grid_pipeline.best_estimator_.named_steps['pca']\n",
        "first_pc_variance = best_pca.explained_variance_[0]\n",
        "print(\"Eigenvalue (variance) of the first principal component:\", first_pc_variance)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5xdcpIsJPIn",
        "outputId": "abb0e6f5-0c84-479f-85f5-fccae78f9f17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eigenvalue (variance) of the first principal component: 1.1635075742239045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q9 Create a pipeline of the PolynomialFeatures as transformer and Lasso as an estimator with the following parameters:\n",
        "  - For PolynomialFeatures:\n",
        "    - interaction_only = False\n",
        "    - degree = 2\n",
        "  - For Lasso:\n",
        "    - alpha = 1\n",
        "    - warm_start = True\n",
        "    - random state as 0\n",
        "\n",
        "Fit the pipeline on the training dataset and find the $R^2$ score on the test dataset."
      ],
      "metadata": {
        "id": "hBuuiUSoFxwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "poly_lasso_pipeline = Pipeline([\n",
        "    ('poly', PolynomialFeatures(degree=2, interaction_only=False)),\n",
        "    ('lasso', Lasso(alpha=1, warm_start=True, random_state=0))\n",
        "])\n",
        "poly_lasso_pipeline.fit(X_train, y_train)\n",
        "r2_poly_lasso = poly_lasso_pipeline.score(X_test, y_test)\n",
        "print(\"R^2 score on test dataset from PolynomialFeatures + Lasso pipeline:\", r2_poly_lasso)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRhMTvQsFUc6",
        "outputId": "d4a718c5-dd8b-4372-bd17-04357d62e09b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R^2 score on test dataset from PolynomialFeatures + Lasso pipeline: 0.157678032410551\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q10 If you eliminate 1 feature with recursive feature elimination, which feature will be eliminated?\n",
        "\n",
        "Type the index of the eliminated feature (index starts from 0).\n",
        "\n",
        "Use LinearRegression model with default parameters as an estimator.\n",
        "Use processed training data.\n"
      ],
      "metadata": {
        "id": "kBVEmK25JglF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "# Set n_features_to_select to total number of features minus 1 (i.e. eliminate 1 feature)\n",
        "rfe = RFE(estimator=lin_reg, n_features_to_select=X_train.shape[1] - 1)\n",
        "rfe.fit(X_train, y_train)\n",
        "# The eliminated feature will have a ranking higher than 1 (selected features have rank 1)\n",
        "eliminated_feature_index = np.where(rfe.ranking_ != 1)[0][0]\n",
        "print(\"Index of the eliminated feature by RFE:\", eliminated_feature_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ql2jK8NuJnwc",
        "outputId": "bb78981f-9041-4713-fef0-782451994b59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index of the eliminated feature by RFE: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TOqFKwQuJ6FW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}