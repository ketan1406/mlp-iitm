{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMxFVmORRqmmZDK4SkCOG8J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9W8sGFDkYhwn","executionInfo":{"status":"ok","timestamp":1741531836364,"user_tz":-330,"elapsed":24516,"user":{"displayName":"24DS2000071 KETAN SAINI","userId":"09541276271295601432"}},"outputId":"dc4063d6-edc2-4299-f4c9-722ea9a7235e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","df = pd.read_csv('/content/drive/MyDrive/MLP/GA/Week8/data_for_large_scale.csv')"],"metadata":{"id":"_USBqrNrYnOA","executionInfo":{"status":"ok","timestamp":1741531867589,"user_tz":-330,"elapsed":1754,"user":{"displayName":"24DS2000071 KETAN SAINI","userId":"09541276271295601432"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, Normalizer\n","from sklearn.linear_model import SGDRegressor\n","from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, f1_score\n","from sklearn.datasets import load_iris\n","from sklearn.neighbors import KNeighborsClassifier\n"],"metadata":{"id":"aKglTrz0Y2Gg","executionInfo":{"status":"ok","timestamp":1741532546654,"user_tz":-330,"elapsed":753,"user":{"displayName":"24DS2000071 KETAN SAINI","userId":"09541276271295601432"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["print(\"First five rows of the dataset:\")\n","print(df.head())\n","\n","# Step 3: Separate features (X) and target (y)\n","X = df.drop(columns=['Target'])\n","y = df['Target']\n","\n","# Step 4: Convert dataframe X and series y into arrays\n","X_array = X.values\n","y_array = y.values\n","\n","# Step 5: Split the dataset (test_size=0.3 and random_state=10)\n","X_train, X_test, y_train, y_test = train_test_split(X_array, y_array, test_size=0.3, random_state=10)\n","\n","# Step 6: Reshape the dataset so each entry has 90 samples\n","# Determine how many complete blocks of 90 samples we have\n","n_samples = 90\n","num_train_samples = (len(X_train) // n_samples) * n_samples\n","num_test_samples = (len(X_test) // n_samples) * n_samples\n","\n","# Reshape the arrays\n","X_train = X_train[:num_train_samples].reshape(-1, n_samples, X_train.shape[1])\n","y_train = y_train[:num_train_samples].reshape(-1, n_samples)\n","X_test = X_test[:num_test_samples].reshape(-1, n_samples, X_test.shape[1])\n","y_test = y_test[:num_test_samples].reshape(-1, n_samples)\n","\n","# Step 7: Initialize and train the SGDRegressor using partial_fit for 5 iterations\n","sgd_regressor = SGDRegressor(random_state=10, max_iter=1, warm_start=True)\n","\n","# Train for 5 iterations over the training batches\n","for iteration in range(5):\n","    for i in range(X_train.shape[0]):\n","        sgd_regressor.partial_fit(X_train[i], y_train[i])\n","\n","# Step 8: Evaluate the model using the test set\n","# Predict on each batch and then concatenate predictions\n","y_pred = np.concatenate([sgd_regressor.predict(X_test[i]) for i in range(X_test.shape[0])])\n","mse = mean_squared_error(y_test.flatten(), y_pred)\n","r2 = r2_score(y_test.flatten(), y_pred)\n","\n","# Extract model parameters\n","intercept = sgd_regressor.intercept_[0]\n","coefficients = sgd_regressor.coef_\n","feature_3_coeff = coefficients[2]  # Assuming zero-index: feature-3 is at index 2\n","feature_5_coeff = coefficients[4]  # Assuming feature-5 is at index 4\n","\n","# Print the answers to the questions\n","print(\"\\nResults:\")\n","print(\"1. Number of features in the dataset:\", X.shape[1])\n","print(\"2. Intercept value (closest answer):\", intercept)\n","print(\"3. Coefficient corresponding to 'Feature-3':\", feature_3_coeff)\n","print(\"4. R² score for test data:\", r2)\n","print(\"5. Coefficient corresponding to 'Feature-5' after 5 iterations:\", feature_5_coeff)\n","print(\"Mean Squared Error on test data:\", mse)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8qEdDuWYY9b2","executionInfo":{"status":"ok","timestamp":1741531926028,"user_tz":-330,"elapsed":3218,"user":{"displayName":"24DS2000071 KETAN SAINI","userId":"09541276271295601432"}},"outputId":"228a4e69-de25-47ac-9b14-1ef1488fda64"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["First five rows of the dataset:\n","   Feature-1  Feature-2  Feature-3  Feature-4  Feature-5  Feature-6  \\\n","0     -1.580     1.0500      1.060     -0.440      0.451    -0.0348   \n","1     -0.832    -0.8660     -1.340      0.138      1.180     0.7330   \n","2     -0.237     2.0900     -3.930      0.296      0.352    -0.5010   \n","3     -1.170    -1.1300     -1.090      1.120      0.312     0.1830   \n","4      0.260    -0.0273      0.925     -1.150     -1.390     0.0251   \n","\n","   Feature-7  Feature-8  Feature-9  Feature-10  Target  \n","0      0.643     0.2650      0.268      -0.851    84.7  \n","1     -1.410     0.1350     -0.088      -1.550  -211.0  \n","2      0.961    -0.0287      1.820       0.938   -96.9  \n","3      0.448    -0.8190     -1.010      -1.080  -152.0  \n","4      0.627     0.0950     -0.280      -0.848   -57.7  \n","\n","Results:\n","1. Number of features in the dataset: 10\n","2. Intercept value (closest answer): -0.003559159504897959\n","3. Coefficient corresponding to 'Feature-3': 81.23931579719752\n","4. R² score for test data: 0.9999919872765453\n","5. Coefficient corresponding to 'Feature-5' after 5 iterations: 76.46726120393859\n","Mean Squared Error on test data: 0.3055324176716899\n"]}]},{"cell_type":"code","source":["# Dataset URL and column names\n","url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00246/3D_spatial_network.txt\"\n","col_names = ['OSM_ID', 'LONGITUDE', 'LATITUDE', 'ALTITUDE']\n","\n","# Parameters for reading in chunks\n","chunksize = 20000\n","\n","# ----- Step 1: First Pass - Scale the Data and Count Total Samples -----\n","scaler = StandardScaler()\n","total_samples = 0\n","\n","# Create an iterator for the dataset, note the separator is comma\n","data_iter = pd.read_csv(url, sep=\",\", header=None, names=col_names, chunksize=chunksize, iterator=True)\n","\n","# Process each chunk to update the scaler and count samples\n","for chunk in data_iter:\n","    total_samples += len(chunk)\n","    # Extract features to be scaled: OSM_ID, LONGITUDE, LATITUDE\n","    X_chunk = chunk[['OSM_ID', 'LONGITUDE', 'LATITUDE']].values.astype(float)\n","    scaler.partial_fit(X_chunk)\n","\n","print(\"Total number of samples in the dataset:\", total_samples)\n","# (Use the printed number to answer Q6)\n","\n","# ----- Step 2: Train the SGDRegressor using partial_fit in 7 iterations -----\n","# Initialize the SGDRegressor with random_state=10 and warm_start=True so that\n","# we can call partial_fit repeatedly without reinitializing the model.\n","sgd_reg = SGDRegressor(random_state=10, warm_start=True)\n","\n","n_epochs = 7\n","for epoch in range(n_epochs):\n","    # Reinitialize the iterator for each epoch\n","    data_iter = pd.read_csv(url, sep=\",\", header=None, names=col_names, chunksize=chunksize, iterator=True)\n","    for chunk in data_iter:\n","        # Prepare features and target\n","        X_chunk = chunk[['OSM_ID', 'LONGITUDE', 'LATITUDE']].values.astype(float)\n","        y_chunk = chunk['ALTITUDE'].values.astype(float)\n","\n","        # Scale features using the fitted scaler\n","        X_chunk_scaled = scaler.transform(X_chunk)\n","\n","        # Incrementally train the model on this chunk\n","        sgd_reg.partial_fit(X_chunk_scaled, y_chunk)\n","\n","# ----- Step 3: Report the Model Parameters -----\n","# The intercept and coefficients are available after the 7th iteration.\n","print(\"\\nModel Parameters after 7 iterations:\")\n","print(\"Intercept (closest option):\", sgd_reg.intercept_[0])\n","print(\"Coefficient for LONGITUDE (closest option):\", sgd_reg.coef_[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8qZMsWU0ZEBD","executionInfo":{"status":"ok","timestamp":1741532356616,"user_tz":-330,"elapsed":5197,"user":{"displayName":"24DS2000071 KETAN SAINI","userId":"09541276271295601432"}},"outputId":"4204229c-7faa-4ca0-a231-787647065c3d"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of samples in the dataset: 434874\n","\n","Model Parameters after 7 iterations:\n","Intercept (closest option): 20.950528897559135\n","Coefficient for LONGITUDE (closest option): 2.7507401692594216\n"]}]},{"cell_type":"code","source":["# Step 1: Load Iris dataset and split (test_size=0.2, random_state=10)\n","iris = load_iris()\n","X, y = iris.data, iris.target\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n","\n","# Step 2: Scale the data using Normalizer\n","normalizer = Normalizer()\n","X_train_norm = normalizer.fit_transform(X_train)\n","X_test_norm = normalizer.transform(X_test)\n","\n","# Step 3: Evaluate KNN classifier for different k values\n","k_values = [2, 3, 4]\n","accuracies = {}\n","\n","print(\"Test set accuracy for different k values:\")\n","for k in k_values:\n","    knn = KNeighborsClassifier(n_neighbors=k)\n","    knn.fit(X_train_norm, y_train)\n","    y_pred = knn.predict(X_test_norm)\n","    acc = accuracy_score(y_test, y_pred)\n","    accuracies[k] = acc\n","    print(f\"k = {k}: Accuracy = {acc:.2f}\")\n","\n","# Determine which k gave the best accuracy\n","best_k = max(accuracies, key=accuracies.get)\n","print(\"\\nBest k value based on test set accuracy:\", best_k)\n","\n","# For k = 3: Compute accuracy and weighted F1 score\n","knn_k3 = KNeighborsClassifier(n_neighbors=3)\n","knn_k3.fit(X_train_norm, y_train)\n","y_pred_k3 = knn_k3.predict(X_test_norm)\n","accuracy_k3 = accuracy_score(y_test, y_pred_k3)\n","f1_weighted_k3 = f1_score(y_test, y_pred_k3, average='weighted')\n","\n","print(\"\\nFor k = 3:\")\n","print(\"Test Accuracy:\", accuracy_k3)\n","print(\"Weighted F1 Score:\", f1_weighted_k3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fL8E1CYnaINo","executionInfo":{"status":"ok","timestamp":1741532556154,"user_tz":-330,"elapsed":56,"user":{"displayName":"24DS2000071 KETAN SAINI","userId":"09541276271295601432"}},"outputId":"b8ebb6f9-52fa-481a-87df-fb2a1f676fd0"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Test set accuracy for different k values:\n","k = 2: Accuracy = 0.97\n","k = 3: Accuracy = 0.97\n","k = 4: Accuracy = 0.97\n","\n","Best k value based on test set accuracy: 2\n","\n","For k = 3:\n","Test Accuracy: 0.9666666666666667\n","Weighted F1 Score: 0.9671111111111111\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"rFe8Ji5vbenH"},"execution_count":null,"outputs":[]}]}